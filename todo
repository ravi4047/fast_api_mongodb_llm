[-]  28-05-25 02:35 Set the LLM response based on the response jsons.

"_1":"How should I return these kinds of things. How will the client handle it either? Hmm client can handle it. It's just a simple programming.",
    "_2":"Let's talk in server side. First Ravi, you think about it. Then ask the Claude about it.",
    "_3": "Source is Gemini android one.",
    "_4": "I think it needs version also",
    "_5": "As far as I can think, It will simply instruct the agent prompt to output it based on this json format.",
    "_6": "I will tell the Claude or AI to use your own creativity as this one is made up.",
    "_7": "Also whether this approach using text or json which one is preferred. Use the most common or better one",



29-05-25 ðŸŸ§ - Implement rate limiting on bio or chatbot part.
ðŸ‘‰ - Actually if there I can't find any solution, I will switch to openai which has max tokens limit.
https://stackoverflow.com/questions/65491184/ratelimit-in-fastapi


16:13 29-05-25 Bio Maker done. Moving to match making
    => Going to write match making all by myself.

ðŸŸ§ I will create a WhatsApp Like animation between different bots entry and exit.

ðŸŸ§ How should I design this conversation bot?
ðŸ‘‰ - Should I make it like help me now what next? Or should I take input or any user description from user?
If that's the case, then I should ask every time, and don't need to introduce any character. Let the user only talk to me. In this way 
it will be very user focused and more original to the thinking of the user.
